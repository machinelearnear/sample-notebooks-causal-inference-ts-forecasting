{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTdWL69xIc_S"
   },
   "source": [
    "# Forecasting with Chronos\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/stable/docs/tutorials/timeseries/forecasting-chronos.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/stable/docs/tutorials/timeseries/forecasting-chronos.ipynb)\n",
    "\n",
    "AutoGluon-TimeSeries (AG-TS) now features [Chronos](https://github.com/amazon-science/chronos-forecasting), a family of pretrained time series forecasting models. Chronos models are based on language model architectures, and work by quantizing time series into buckets which are treated as tokens. Language models are then trained on these token sequences using cross-entropy loss.\n",
    "\n",
    "The current iteration of Chronos models, [available](https://huggingface.co/amazon/chronos-t5-large) on Hugging Face ðŸ¤—, is based on the T5 architecture and was trained on a large corpus of open-source time series data augmented with synthetic data generation techniques. The Chronos [paper](https://arxiv.org/abs/2403.07815) provides greater detail about the models and how they were trained.\n",
    "\n",
    "AG-TS provides a robust and easy way to use Chronos through the familiar `TimeSeriesPredictor` API.\n",
    "- Chronos can be combined with other forecasting models to build accurate ensembles using the `\"high_quality\"` and `\"best_quality\"` presets.\n",
    "- Alternatively, Chronos can be used as a standalone zero-shot model with presets such as `\"chronos_small\"` or `\"chronos_base\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wzl_9pHhIc_W",
    "tags": [
     "remove-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# # We use uv for faster installation\n",
    "# !pip install uv\n",
    "# !uv pip install -q autogluon.timeseries --system\n",
    "# !uv pip uninstall -q torchaudio torchvision torchtext --system # fix incompatible package versions on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YsNKA0B-Ic_X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqZ3Eh40Ic_Y",
    "tags": []
   },
   "source": [
    "## Getting Started with Chronos\n",
    "\n",
    "Chronos is available in 5 model sizes with different numbers of parameters: `tiny` (8M), `mini` (20M), `small` (46M), `base` (200M), and `large` (710M). Being a pretrained model for zero-shot forecasting, Chronos is different from other models available in AG-TS.\n",
    "Specifically, Chronos models do not really `fit` time series data. However, when `predict` is called, they carry out a relatively more expensive computation that scales linearly with the number of time series in the dataset. In this aspect, they behave like local statistical models such as ETS or ARIMA, where expensive computation happens during inference. Differently from statistical models, however, computation in the larger Chronos models requires an accelerator chip to run in a reasonable amount of time.\n",
    "\n",
    "The easiest way to get started with Chronos is through model-specific presets available in the `TimeSeriesPredictor`. As of v1.1, the `TimeSeriesPredictor.fit` method has a separate Chronos preset for each model size, such as `\"chronos_small\"` or `\"chronos_base\"`.\n",
    "\n",
    "Alternatively, Chronos can be combined with other time series models using presets `\"chronos_ensemble\"`, `\"chronos_large_ensemble\"`, `\"high_quality\"` and `\"best_quality\"`. More details about these presets are available in the documentation for [`TimeSeriesPredictor.fit`](https://auto.gluon.ai/stable/api/autogluon.timeseries.TimeSeriesPredictor.fit.html).\n",
    "\n",
    "Note that the model sizes `small` and higher require a GPU to run. However, models `tiny` and `mini` can be run on the CPU as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixFpk-gFIc_Y"
   },
   "source": [
    "\n",
    "Let's work with a subset of the M4 competition data set to see Chronos-tiny in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/ECM_R_output.csv')\n",
    "df['timestamp'] = pd.to_datetime(df.index)\n",
    "df['item_id'] = \"test\"\n",
    "df = df.rename(columns={'ln_cons': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>ln_rhdi</th>\n",
       "      <th>ln_liquid_wealth_realcpi</th>\n",
       "      <th>ln_illiquid_wealth_realcpi</th>\n",
       "      <th>ln_real_hp</th>\n",
       "      <th>unemp</th>\n",
       "      <th>nom_r</th>\n",
       "      <th>covid</th>\n",
       "      <th>dln_cons</th>\n",
       "      <th>dln_rhdi</th>\n",
       "      <th>dln_liquid_wealth_realcpi</th>\n",
       "      <th>dln_illiquid_wealth_realcpi</th>\n",
       "      <th>dln_real_hp</th>\n",
       "      <th>dunemp</th>\n",
       "      <th>dnom_r</th>\n",
       "      <th>dcovid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/01/1986</td>\n",
       "      <td>11.974594</td>\n",
       "      <td>12.011729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00.000000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/1987</td>\n",
       "      <td>11.986267</td>\n",
       "      <td>11.998113</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>11.1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>-0.013616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00.000000001</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/01/1987</td>\n",
       "      <td>12.002609</td>\n",
       "      <td>12.020610</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.022497</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00.000000002</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/01/1987</td>\n",
       "      <td>12.023357</td>\n",
       "      <td>12.034163</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020748</td>\n",
       "      <td>0.013553</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00.000000003</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/01/1987</td>\n",
       "      <td>12.044694</td>\n",
       "      <td>12.041051</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00.000000004</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index     target    ln_rhdi ln_liquid_wealth_realcpi  \\\n",
       "0  10/01/1986  11.974594  12.011729                      NaN   \n",
       "1  01/01/1987  11.986267  11.998113                    #NUM!   \n",
       "2  04/01/1987  12.002609  12.020610                    #NUM!   \n",
       "3  07/01/1987  12.023357  12.034163                    #NUM!   \n",
       "4  10/01/1987  12.044694  12.041051                    #NUM!   \n",
       "\n",
       "  ln_illiquid_wealth_realcpi ln_real_hp  unemp  nom_r  covid  dln_cons  \\\n",
       "0                        NaN      #NUM!   11.3  10.72      0  0.005346   \n",
       "1                      #NUM!      #NUM!   11.1  10.66      0  0.011673   \n",
       "2                      #NUM!      #NUM!   10.7   9.21      0  0.016342   \n",
       "3                      #NUM!      #NUM!   10.2   9.48      0  0.020748   \n",
       "4                      #NUM!      #NUM!    9.7   9.04      0  0.021337   \n",
       "\n",
       "   dln_rhdi dln_liquid_wealth_realcpi dln_illiquid_wealth_realcpi dln_real_hp  \\\n",
       "0  0.001489                       NaN                         NaN       #NUM!   \n",
       "1 -0.013616                       NaN                         NaN       #NUM!   \n",
       "2  0.022497                     #NUM!                       #NUM!       #NUM!   \n",
       "3  0.013553                     #NUM!                       #NUM!       #NUM!   \n",
       "4  0.006888                     #NUM!                       #NUM!       #NUM!   \n",
       "\n",
       "   dunemp  dnom_r  dcovid                     timestamp item_id  \n",
       "0    -0.1    0.84       0 1970-01-01 00:00:00.000000000    test  \n",
       "1    -0.2   -0.06       0 1970-01-01 00:00:00.000000001    test  \n",
       "2    -0.4   -1.45       0 1970-01-01 00:00:00.000000002    test  \n",
       "3    -0.5    0.27       0 1970-01-01 00:00:00.000000003    test  \n",
       "4    -0.5   -0.44       0 1970-01-01 00:00:00.000000004    test  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "86oh-Jj3Ic_Y",
    "outputId": "dc6e87f6-ffa5-45d8-9618-0e5305b562df",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>ln_rhdi</th>\n",
       "      <th>ln_liquid_wealth_realcpi</th>\n",
       "      <th>ln_illiquid_wealth_realcpi</th>\n",
       "      <th>ln_real_hp</th>\n",
       "      <th>unemp</th>\n",
       "      <th>nom_r</th>\n",
       "      <th>covid</th>\n",
       "      <th>dln_cons</th>\n",
       "      <th>dln_rhdi</th>\n",
       "      <th>dln_liquid_wealth_realcpi</th>\n",
       "      <th>dln_illiquid_wealth_realcpi</th>\n",
       "      <th>dln_real_hp</th>\n",
       "      <th>dunemp</th>\n",
       "      <th>dnom_r</th>\n",
       "      <th>dcovid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">test</th>\n",
       "      <th>1970-01-01 00:00:00.000000000</th>\n",
       "      <td>10/01/1986</td>\n",
       "      <td>11.974594</td>\n",
       "      <td>12.011729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000001</th>\n",
       "      <td>01/01/1987</td>\n",
       "      <td>11.986267</td>\n",
       "      <td>11.998113</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>11.1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>-0.013616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000002</th>\n",
       "      <td>04/01/1987</td>\n",
       "      <td>12.002609</td>\n",
       "      <td>12.020610</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.022497</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000003</th>\n",
       "      <td>07/01/1987</td>\n",
       "      <td>12.023357</td>\n",
       "      <td>12.034163</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020748</td>\n",
       "      <td>0.013553</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000004</th>\n",
       "      <td>10/01/1987</td>\n",
       "      <td>12.044694</td>\n",
       "      <td>12.041051</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            index     target    ln_rhdi  \\\n",
       "item_id timestamp                                                         \n",
       "test    1970-01-01 00:00:00.000000000  10/01/1986  11.974594  12.011729   \n",
       "        1970-01-01 00:00:00.000000001  01/01/1987  11.986267  11.998113   \n",
       "        1970-01-01 00:00:00.000000002  04/01/1987  12.002609  12.020610   \n",
       "        1970-01-01 00:00:00.000000003  07/01/1987  12.023357  12.034163   \n",
       "        1970-01-01 00:00:00.000000004  10/01/1987  12.044694  12.041051   \n",
       "\n",
       "                                      ln_liquid_wealth_realcpi  \\\n",
       "item_id timestamp                                                \n",
       "test    1970-01-01 00:00:00.000000000                      NaN   \n",
       "        1970-01-01 00:00:00.000000001                    #NUM!   \n",
       "        1970-01-01 00:00:00.000000002                    #NUM!   \n",
       "        1970-01-01 00:00:00.000000003                    #NUM!   \n",
       "        1970-01-01 00:00:00.000000004                    #NUM!   \n",
       "\n",
       "                                      ln_illiquid_wealth_realcpi ln_real_hp  \\\n",
       "item_id timestamp                                                             \n",
       "test    1970-01-01 00:00:00.000000000                        NaN      #NUM!   \n",
       "        1970-01-01 00:00:00.000000001                      #NUM!      #NUM!   \n",
       "        1970-01-01 00:00:00.000000002                      #NUM!      #NUM!   \n",
       "        1970-01-01 00:00:00.000000003                      #NUM!      #NUM!   \n",
       "        1970-01-01 00:00:00.000000004                      #NUM!      #NUM!   \n",
       "\n",
       "                                       unemp  nom_r  covid  dln_cons  \\\n",
       "item_id timestamp                                                      \n",
       "test    1970-01-01 00:00:00.000000000   11.3  10.72      0  0.005346   \n",
       "        1970-01-01 00:00:00.000000001   11.1  10.66      0  0.011673   \n",
       "        1970-01-01 00:00:00.000000002   10.7   9.21      0  0.016342   \n",
       "        1970-01-01 00:00:00.000000003   10.2   9.48      0  0.020748   \n",
       "        1970-01-01 00:00:00.000000004    9.7   9.04      0  0.021337   \n",
       "\n",
       "                                       dln_rhdi dln_liquid_wealth_realcpi  \\\n",
       "item_id timestamp                                                           \n",
       "test    1970-01-01 00:00:00.000000000  0.001489                       NaN   \n",
       "        1970-01-01 00:00:00.000000001 -0.013616                       NaN   \n",
       "        1970-01-01 00:00:00.000000002  0.022497                     #NUM!   \n",
       "        1970-01-01 00:00:00.000000003  0.013553                     #NUM!   \n",
       "        1970-01-01 00:00:00.000000004  0.006888                     #NUM!   \n",
       "\n",
       "                                      dln_illiquid_wealth_realcpi dln_real_hp  \\\n",
       "item_id timestamp                                                               \n",
       "test    1970-01-01 00:00:00.000000000                         NaN       #NUM!   \n",
       "        1970-01-01 00:00:00.000000001                         NaN       #NUM!   \n",
       "        1970-01-01 00:00:00.000000002                       #NUM!       #NUM!   \n",
       "        1970-01-01 00:00:00.000000003                       #NUM!       #NUM!   \n",
       "        1970-01-01 00:00:00.000000004                       #NUM!       #NUM!   \n",
       "\n",
       "                                       dunemp  dnom_r  dcovid  \n",
       "item_id timestamp                                              \n",
       "test    1970-01-01 00:00:00.000000000    -0.1    0.84       0  \n",
       "        1970-01-01 00:00:00.000000001    -0.2   -0.06       0  \n",
       "        1970-01-01 00:00:00.000000002    -0.4   -1.45       0  \n",
       "        1970-01-01 00:00:00.000000003    -0.5    0.27       0  \n",
       "        1970-01-01 00:00:00.000000004    -0.5   -0.44       0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TimeSeriesDataFrame(\n",
    "    df,\n",
    "    id_column = \"item_id\",\n",
    "    timestamp_column = \"timestamp\",\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select = [x for x in list(df.columns) if x not in ['index', 'target', 'timestamp', 'item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ndEdOPOdIc_Z",
    "outputId": "b25c4822-b6cb-4362-95b3-387561079fb3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'AutogluonModels/ag-20240821_102830'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Tue May 21 16:52:24 UTC 2024\n",
      "CPU Count:          8\n",
      "GPU Count:          1\n",
      "Memory Avail:       26.19 GB / 30.99 GB (84.5%)\n",
      "Disk Space Avail:   466.92 GB / 491.96 GB (94.9%)\n",
      "===================================================\n",
      "Setting presets to: best_quality\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': ['ln_rhdi',\n",
      "                            'ln_liquid_wealth_realcpi',\n",
      "                            'ln_illiquid_wealth_realcpi',\n",
      "                            'ln_real_hp',\n",
      "                            'unemp',\n",
      "                            'nom_r',\n",
      "                            'covid',\n",
      "                            'dln_cons',\n",
      "                            'dln_rhdi',\n",
      "                            'dln_liquid_wealth_realcpi',\n",
      "                            'dln_illiquid_wealth_realcpi',\n",
      "                            'dln_real_hp',\n",
      "                            'dunemp',\n",
      "                            'dnom_r',\n",
      "                            'dcovid'],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 24,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'verbosity': 2}\n",
      "\n",
      "Inferred time series frequency: 'ns'\n",
      "Provided train_data has 146 rows, 1 time series. Median time series length is 146 (min=146, max=146). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\tknown_covariates:\n",
      "\t\tcategorical:        ['ln_liquid_wealth_realcpi']\n",
      "\t\tcontinuous (float): ['ln_rhdi', 'unemp', 'nom_r', 'covid', 'dln_cons', 'dln_rhdi', ...]\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): []\n",
      "\n",
      "AutoGluon will ignore following non-numeric/non-informative columns:\n",
      "\tignored covariates:      ['dln_illiquid_wealth_realcpi', 'dln_liquid_wealth_realcpi', 'dln_real_hp', 'index', 'ln_illiquid_wealth_realcpi', 'ln_real_hp']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-08-21 10:28:30\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'CrostonSBA', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'AutoARIMA', 'Chronos[base]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST']\n",
      "Training timeseries model SeasonalNaive. \n",
      "\t-0.0035       = Validation score (-WQL)\n",
      "\t1.07    s     = Training runtime\n",
      "\t0.79    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. \n",
      "\t-0.0018       = Validation score (-WQL)\n",
      "\t3.22    s     = Training runtime\n",
      "\t0.28    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. \n",
      "\t-0.0055       = Validation score (-WQL)\n",
      "\t7.64    s     = Training runtime\n",
      "\t0.21    s     = Validation (prediction) runtime\n",
      "Training timeseries model CrostonSBA. \n",
      "\t-0.0320       = Validation score (-WQL)\n",
      "\t6.87    s     = Training runtime\n",
      "\t6.90    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. \n",
      "\t-0.0138       = Validation score (-WQL)\n",
      "\t0.06    s     = Training runtime\n",
      "\t0.04    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. \n",
      "\t-0.0025       = Validation score (-WQL)\n",
      "\t13.02   s     = Training runtime\n",
      "\t16.41   s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. \n",
      "\t-0.0047       = Validation score (-WQL)\n",
      "\t12.97   s     = Training runtime\n",
      "\t16.34   s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoARIMA. \n",
      "\t-0.0035       = Validation score (-WQL)\n",
      "\t8.76    s     = Training runtime\n",
      "\t8.84    s     = Validation (prediction) runtime\n",
      "Training timeseries model Chronos[base]. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2dc508ec744ce281342a08b3921944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb3312f19ad49ebbddb17587e710b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/806M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decaae8be0084a1981cc7f8faff42d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0055       = Validation score (-WQL)\n",
      "\t3.41    s     = Training runtime\n",
      "\t1.04    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. \n",
      "\t-0.0051       = Validation score (-WQL)\n",
      "\t86.28   s     = Training runtime\n",
      "\t0.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. \n",
      "\t-0.0039       = Validation score (-WQL)\n",
      "\t33.65   s     = Training runtime\n",
      "\t0.09    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. \n",
      "\t-0.0037       = Validation score (-WQL)\n",
      "\t75.29   s     = Training runtime\n",
      "\t0.01    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'DirectTabular': 0.16, 'RecursiveTabular': 0.72, 'SeasonalNaive': 0.01, 'TemporalFusionTransformer': 0.11}\n",
      "\t-0.0016       = Validation score (-WQL)\n",
      "\t1.99    s     = Training runtime\n",
      "\t1.31    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'CrostonSBA', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'AutoARIMA', 'Chronos[base]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'WeightedEnsemble']\n",
      "Total runtime: 305.32 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.0016\n"
     ]
    }
   ],
   "source": [
    "prediction_length = 24\n",
    "train_data, test_data = data.train_test_split(prediction_length)\n",
    "\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=prediction_length,\n",
    "    known_covariates_names=select,\n",
    ").fit(\n",
    "    train_data, presets=\"best_quality\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ID15jnqCIc_a"
   },
   "source": [
    "As promised, Chronos does not take any time to `fit`. The `fit` call merely serves as a proxy for the `TimeSeriesPredictor` to do some of its chores under the hood, such as inferring the frequency of time series and saving the predictor's state to disk.\n",
    "\n",
    "Let's use the `predict` method to generate forecasts, and the `plot` method to visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_dataset = train_data[select].tail(prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">test</th>\n",
       "      <th>1970-01-01 00:00:00.000000146</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000147</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000148</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000149</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000150</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(test, 1970-01-01 00:00:00.000000146), (test, 1970-01-01 00:00:00.000000147), (test, 1970-01-01 00:00:00.000000148), (test, 1970-01-01 00:00:00.000000149), (test, 1970-01-01 00:00:00.000000150)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.timeseries.utils.forecast import get_forecast_horizon_index_ts_dataframe\n",
    "\n",
    "future_index = get_forecast_horizon_index_ts_dataframe(train_data, prediction_length=24)\n",
    "future_timestamps = future_index.get_level_values(\"timestamp\")\n",
    "known_covariates = pd.DataFrame(index=future_index)\n",
    "known_covariates[\"weekend\"] = future_timestamps.weekday.isin(train_data.tail(prediction_length)).astype(float)\n",
    "\n",
    "known_covariates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "UMBLhwV7Ic_a",
    "outputId": "11261186-5b10-4f0b-fb71-1c2cca22ad46",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "known_covariates should include the values for prediction_length=24 many time steps into the future.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/autogluon/timeseries/learner.py:165\u001b[0m, in \u001b[0;36mTimeSeriesLearner._align_covariates_with_forecast_index\u001b[0;34m(self, known_covariates, data)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     known_covariates \u001b[38;5;241m=\u001b[39m \u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mforecast_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/pandas/core/indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/pandas/core/indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/pandas/core/indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/pandas/core/indexes/multi.py:2766\u001b[0m, in \u001b[0;36mMultiIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   2764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[indexer], indexer\n\u001b[0;32m-> 2766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/pandas/core/indexes/multi.py:2786\u001b[0m, in \u001b[0;36mMultiIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [MultiIndex([('test', '1970-01-01 00:00:00.000000146'),\\n            ('test', '1970-01-01 00:00:00.000000147'),\\n            ('test', '1970-01-01 00:00:00.000000148'),\\n            ('test', '1970-01-01 00:00:00.000000149'),\\n            ('test', '1970-01-01 00:00:00.000000150'),\\n            ('test', '1970-01-01 00:00:00.000000151'),\\n            ('test', '1970-01-01 00:00:00.000000152'),\\n            ('test', '1970-01-01 00:00:00.000000153'),\\n            ('test', '1970-01-01 00:00:00.000000154'),\\n            ('test', '1970-01-01 00:00:00.000000155'),\\n            ('test', '1970-01-01 00:00:00.000000156'),\\n            ('test', '1970-01-01 00:00:00.000000157'),\\n            ('test', '1970-01-01 00:00:00.000000158'),\\n            ('test', '1970-01-01 00:00:00.000000159'),\\n            ('test', '1970-01-01 00:00:00.000000160'),\\n            ('test', '1970-01-01 00:00:00.000000161'),\\n            ('test', '1970-01-01 00:00:00.000000162'),\\n            ('test', '1970-01-01 00:00:00.000000163'),\\n            ('test', '1970-01-01 00:00:00.000000164'),\\n            ('test', '1970-01-01 00:00:00.000000165'),\\n            ('test', '1970-01-01 00:00:00.000000166'),\\n            ('test', '1970-01-01 00:00:00.000000167'),\\n            ('test', '1970-01-01 00:00:00.000000168'),\\n            ('test', '1970-01-01 00:00:00.000000169')],\\n           names=['item_id', 'timestamp'])] are in the [index]\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m predictor\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m      3\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m      4\u001b[0m     predictions\u001b[38;5;241m=\u001b[39mpredictions,\n\u001b[1;32m      5\u001b[0m     item_ids\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     max_history_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      7\u001b[0m );\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/autogluon/timeseries/predictor.py:845\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.predict\u001b[0;34m(self, data, known_covariates, model, use_cache, random_seed)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m known_covariates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_data_frame(known_covariates)\n\u001b[0;32m--> 845\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mreindex(original_item_id_order, level\u001b[38;5;241m=\u001b[39mITEMID)\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/autogluon/timeseries/learner.py:184\u001b[0m, in \u001b[0;36mTimeSeriesLearner.predict\u001b[0;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_generator\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m    183\u001b[0m known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_generator\u001b[38;5;241m.\u001b[39mtransform_future_known_covariates(known_covariates)\n\u001b[0;32m--> 184\u001b[0m known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_align_covariates_with_forecast_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_trainer()\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m    186\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    187\u001b[0m     known_covariates\u001b[38;5;241m=\u001b[39mknown_covariates,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    192\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/machinelearnear-ts-causal-inference/lib/python3.10/site-packages/autogluon/timeseries/learner.py:167\u001b[0m, in \u001b[0;36mTimeSeriesLearner._align_covariates_with_forecast_index\u001b[0;34m(self, known_covariates, data)\u001b[0m\n\u001b[1;32m    165\u001b[0m     known_covariates \u001b[38;5;241m=\u001b[39m known_covariates\u001b[38;5;241m.\u001b[39mloc[forecast_index]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknown_covariates should include the values for prediction_length=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmany time steps into the future.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m known_covariates\n",
      "\u001b[0;31mValueError\u001b[0m: known_covariates should include the values for prediction_length=24 many time steps into the future."
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(train_data, known_covariates=pred_dataset)\n",
    "predictor.plot(\n",
    "    data=data,\n",
    "    predictions=predictions,\n",
    "    item_ids=[\"test\"],\n",
    "    max_history_length=200,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyllfXOlIc_a"
   },
   "source": [
    "## Configuring for Performance\n",
    "\n",
    "Looks good! As with all large deep learning models, however, some fine-grained control of inference parameters can be needed to both optimize the speed and avoid out-of-memory issues on specific hardware. For this, we will need to dive a bit deeper, configuring `hyperparameters` of the `TimeSeriesPredictor` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbWd5mtzIc_b"
   },
   "outputs": [],
   "source": [
    "predictor = TimeSeriesPredictor(prediction_length=prediction_length).fit(\n",
    "    train_data,\n",
    "    hyperparameters={\n",
    "        \"Chronos\": {\n",
    "            \"model_path\": \"tiny\",\n",
    "            \"batch_size\": 64,\n",
    "            \"device\": \"cpu\",\n",
    "        }\n",
    "    },\n",
    "    skip_model_selection=True,\n",
    "    verbosity=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCubYl5aIc_b",
    "outputId": "5572a9f6-4386-435d-8a14-1ae9797f55b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 4s, sys: 42.4 s, total: 2min 47s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = predictor.predict(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uALAfqRoIc_b"
   },
   "source": [
    "Above, we used the following configuration options for the `TimeSeriesPredictor`:\n",
    "- we set `skip_model_selection=True` to skip running backtests during `fit`, as we will only consider a single model.\n",
    "- in the `hyperparameters` for the Chronos model,\n",
    "    - `model_path` allows us to change the model size or select different pretrained weights. This parameter can be a model string like `tiny` or `base`, a Hugging Face path like `amazon/chronos-t5-mini`, or a path to a local folder with custom weights.\n",
    "    - `batch_size` configures the number of time series for which predictions are generated in parallel.\n",
    "    - `device` instructs Chronos to run the model on CPU.\n",
    "\n",
    "As we see, inference speed is slower on the CPU compared to the GPU, taking about 400ms per time series.\n",
    "To overcome this limitation, AutoGluon implementation of Chronos supports several deep learning compilers that can optimize model performance on CPUs.\n",
    "\n",
    "For example, we can set `optimization_strategy=\"openvino\"` to use the [OpenVINO](https://github.com/openvinotoolkit/openvino) compiler for Intel CPUs to speed up Chronos inference. Behind the scenes, AutoGluon will use Hugging Face [optimum](https://github.com/huggingface/optimum-intel) for this conversion.\n",
    "\n",
    "Note that this requires installing the optional OpenVINO dependency for AG-TS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v59YoQHfIc_b"
   },
   "outputs": [],
   "source": [
    "!pip install -q \"autogluon.timeseries[chronos-openvino]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pw8FVs5rIc_b"
   },
   "source": [
    "To speed up the inference even further, we can `persist` the model after calling `fit`. The `TimeSeriesPredictor.persist` method tells AutoGluon to keep the Chronos model in device memory for fast, on-demand inference instead of loading the model from disk each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfGgjOF4Ic_c"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "predictor = TimeSeriesPredictor(prediction_length=prediction_length).fit(\n",
    "    train_data,\n",
    "    hyperparameters={\n",
    "        \"Chronos\": {\n",
    "            \"model_path\": \"tiny\",\n",
    "            \"batch_size\": 64,\n",
    "            \"device\": \"cpu\",\n",
    "            \"optimization_strategy\": \"openvino\",\n",
    "        }\n",
    "    },\n",
    "    skip_model_selection=True,\n",
    "    verbosity=0,\n",
    ")\n",
    "predictor.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAjFwjjNIc_c",
    "outputId": "1ce92cdf-cd4c-4101-90a1-fdfc3fe5d611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 9.19 s, total: 1min 17s\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = predictor.predict(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FYZlmkEIc_c"
   },
   "source": [
    "That reduced the inference time by ~3x!\n",
    "\n",
    "We could have also used the ONNX runtime by providing `optimization_strategy=\"onnx\"`. For a discussion of these and other hyperparameters of Chronos, see the Chronos model [documentation](forecasting-model-zoo.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndqQD3O4Ic_c"
   },
   "source": [
    "## FAQ\n",
    "\n",
    "\n",
    "#### How accurate is Chronos?\n",
    "\n",
    "In several independent evaluations we found Chronos to be effective in zero-shot forecasting.\n",
    "The accuracy of Chronos-large often exceeds statistical baseline models, and is often comparable to deep learning\n",
    "models such as `TemporalFusionTransformer` or `PatchTST`.\n",
    "\n",
    "#### What hardware do larger Chronos models require?\n",
    "\n",
    "We tested Chronos on AWS `g5.2xlarge` and `p3.2xlarge` instances that feature NVIDIA A10G and V100 GPUs, with at least 16GiB of GPU memory and 32GiB of main memory.\n",
    "\n",
    "#### Can I fine-tune Chronos?\n",
    "\n",
    "The current iteration of Chronos on AutoGluon does not support fine tuning, although we will provide this functionality in later versions of AutoGluon.\n",
    "\n",
    "#### Does Chronos work with covariates or features?\n",
    "\n",
    "The current iteration of Chronos does not support covariates or features, however we will provide this functionality in\n",
    "later versions. In the meanwhile, presets such as `chronos_ensemble` combine Chronos with models that do take advantage of features.\n",
    "\n",
    "#### Where can I ask specific questions on Chronos?\n",
    "\n",
    "The AutoGluon team are among the core developers of Chronos. So you can ask Chronos-related questions on AutoGluon channels such\n",
    "as the Discord [server](https://discord.gg/wjUmjqAc2N), or [GitHub](https://github.com/autogluon/autogluon). You can also join\n",
    "the discussion on the Chronos GitHub [page](https://github.com/amazon-science/chronos-forecasting/discussions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_machinelearnear-ts-causal-inference",
   "language": "python",
   "name": "conda_machinelearnear-ts-causal-inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
